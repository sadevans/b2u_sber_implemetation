{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from arch_unet import UNet\n",
    "import utils as util\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Sber_utils import Masker, load_network, generate_mask, interpolate_mask, depth_to_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--noisetype\", type=str, default=\"gauss25\", choices=['gauss25', 'gauss5_50', 'poisson30', 'poisson5_50'])\n",
    "parser.add_argument('--checkpoint', type=str, default='./*.pth')\n",
    "parser.add_argument('--test_dir', type=str, default='./data/test')\n",
    "parser.add_argument('--save_test_path', type=str, default='./test')\n",
    "parser.add_argument('--log_name', type=str, default='b2u_unet_g25_112rf20')\n",
    "parser.add_argument('--gpu_devices', default='0', type=str)\n",
    "parser.add_argument('--parallel', action='store_true')\n",
    "parser.add_argument('--n_feature', type=int, default=48)\n",
    "parser.add_argument('--n_channel', type=int, default=1)\n",
    "parser.add_argument(\"--beta\", type=float, default=20.0)\n",
    "parser.add_argument('--dataset_name', type=str)\n",
    "parser.add_argument('--repeat_times', type=int, default=1)\n",
    "parser.add_argument('--_continue', type=bool, default=True)\n",
    "\n",
    "opt = parser.parse_args(['--noisetype', 'gauss5_50', \n",
    "                        # '--checkpoint', './pretrained_models/g5-50_112rf20_beta19.4.pth',\n",
    "                        # '--checkpoint', './experiments/my_models/b2u_second/models/epoch_model_100.pth',\n",
    "                        # '--checkpoint', './experiments/my_models/b2u_first/models/epoch_model_100.pth',\n",
    "                        '--checkpoint', './experiments/my_models/b2u_crystal_first/models/epoch_model_120.pth',\n",
    "                        '--test_dir', './data/test',\n",
    "                        '--save_test_path', './test',\n",
    "                        '--log_name', 'b2u_Crystal_focus_0_dose_180_ep120',\n",
    "                        '--beta', '19.4',\n",
    "                        '--dataset_name', 'Crystal_focus_0_dose_180'])\n",
    "                        \n",
    "systime = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "operation_seed_counter = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_devices\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_cropping():\n",
    "    def __init__(self, img_size, crop_size, margin) -> None:\n",
    "        self.margin = margin\n",
    "        self.img_size = img_size\n",
    "        self.stride_v = crop_size[0] - margin\n",
    "        self.stride_h = crop_size[1] - margin\n",
    "        self.crop_size = crop_size\n",
    "        self.h_steps = int(np.ceil(img_size[1]/self.stride_h))\n",
    "        self.v_steps = int(np.ceil(img_size[0]/self.stride_v))\n",
    "        self.crop_nums = self.h_steps * self.v_steps\n",
    "\n",
    "    def get_position(self, index):\n",
    "        v_step = int(np.floor(index/self.v_steps))\n",
    "        h_step = index - (v_step*self.v_steps)\n",
    "\n",
    "        return v_step, h_step\n",
    "    \n",
    "    \n",
    "    def crop_image(self, img, index):\n",
    "        v_step, h_step = self.get_position(index)\n",
    "\n",
    "        return img[v_step*self.stride_v : v_step*self.stride_v + self.crop_size[0],\n",
    "                                     h_step*self.stride_h : h_step*self.stride_h + self.crop_size[1]]\n",
    "    \n",
    "    def concat(self, img_array):\n",
    "        img = np.empty(self.img_size)\n",
    "        i = 0\n",
    "        for v in range(self.v_steps):\n",
    "            for h in range(self.h_steps):\n",
    "                flag_v = 1\n",
    "                flag_h = 1\n",
    "\n",
    "                if v == 0:\n",
    "                    flag_v = 0\n",
    "                if h == 0:\n",
    "                    flag_h = 0\n",
    "\n",
    "                \n",
    "                img[v*self.stride_v + flag_v * (self.margin//2): v*self.stride_v + self.crop_size[0],\n",
    "                                     h*self.stride_h + flag_h * (self.margin//2):h*self.stride_h + self.crop_size[1]] = img_array[i] [flag_v * (self.margin//2):, flag_h * (self.margin//2):]\n",
    "\n",
    "\n",
    "                i+=1\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_median(img, percentile):\n",
    "    tresh = np.percentile(img.ravel(), percentile)\n",
    "    mask = np.zeros_like(img)\n",
    "    mask[img < tresh] = 1\n",
    "    median_img = cv2.medianBlur(img, 7)\n",
    "    img = img*(1 - mask) + median_img * mask\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopyDataset(Dataset):\n",
    "    def __init__(self, img_dir, cropping, channels=3, transform=None, apply_median=False):\n",
    "        self.cropping_object = cropping\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.crop_nums = cropping.crop_nums\n",
    "        self.img_filenames = os.listdir(img_dir)\n",
    "        self.apply_median = apply_median\n",
    "        if channels == 1:\n",
    "            self.channels = 0\n",
    "        else:\n",
    "            self.channels = channels\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.img_filenames) * self.crop_nums)\n",
    "\n",
    "    def __getitem__(self, crop_idx):\n",
    "        image_idx = crop_idx // self.crop_nums\n",
    "        img_crop_idx = crop_idx % self.crop_nums\n",
    "        # print(f'img index {image_idx}, img_crop_idx {img_crop_idx}')\n",
    "        name = os.path.split(self.img_filenames[image_idx])[-1].split('.')[0]\n",
    "\n",
    "        image = cv2.imread(os.path.join(self.img_dir, self.img_filenames[image_idx]), self.channels)\n",
    "\n",
    "        crop = self.cropping_object.crop_image(image, img_crop_idx)\n",
    "\n",
    "        if self.apply_median:\n",
    "            crop = apply_median(crop, 10)\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            crop = self.transform(crop)\n",
    "\n",
    "        return crop, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all images:  55\n",
      "prepared images:  0\n",
      "rest images:  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (head): Sequential(\n",
       "    (0): LR(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): LR(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_path): ModuleList(\n",
       "    (0-4): 5 x LR(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_path): ModuleList(\n",
       "    (0): UP(\n",
       "      (conv_1): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_2): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-3): 3 x UP(\n",
       "      (conv_1): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_2): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): UP(\n",
       "      (conv_1): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(97, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_2): LR(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last): Sequential(\n",
       "    (0): LR(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): LR(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation\n",
    "save_test_path = os.path.join(opt.save_test_path, opt.dataset_name)\n",
    "os.makedirs(save_test_path, exist_ok=True)\n",
    "\n",
    "validation_path = os.path.join(save_test_path, opt.log_name)\n",
    "os.makedirs(validation_path, exist_ok=True)\n",
    "np.random.seed(101)\n",
    "\n",
    "\n",
    "# Dataset\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "dataset_dir = os.path.join(opt.test_dir, opt.dataset_name)\n",
    "cropping = Image_cropping((768, 1024), (768, 1024), 0)\n",
    "test_dataset = MicroscopyDataset(dataset_dir, cropping, opt.n_channel, transform=test_transforms, apply_median=False)\n",
    "if opt._continue == True:\n",
    "    ready_filenames = os.listdir(validation_path)\n",
    "    ready_filenames = [x.split('.')[0] for x in ready_filenames]\n",
    "    filenames = os.listdir(dataset_dir)\n",
    "    print('all images: ', len(filenames))\n",
    "    print('prepared images: ', len(ready_filenames))\n",
    "\n",
    "    rest_filenames = [x for x in filenames if x.split('.')[0] not in ready_filenames]\n",
    "    print('rest images: ', len(rest_filenames))\n",
    "    test_dataset.img_filenames = rest_filenames\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Masker\n",
    "masker = Masker(width=2, mode='interpolate', mask_type='all')\n",
    "# Network\n",
    "network = UNet(in_channels=opt.n_channel,\n",
    "                out_channels=opt.n_channel,\n",
    "                wf=opt.n_feature)\n",
    "if opt.parallel:\n",
    "    network = torch.nn.DataParallel(network)\n",
    "network = network.cuda()\n",
    "# load pre-trained model\n",
    "network = load_network(opt.checkpoint, network, strict=True)\n",
    "beta = opt.beta\n",
    "\n",
    "# turn on eval mode\n",
    "network.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:24<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = validation_path\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "repeat_times = opt.repeat_times\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    mid = []\n",
    "    for im, name in tqdm(test_dataloader):\n",
    "        \n",
    "        if type(im) == torch.Tensor:\n",
    "            \n",
    "            if len(im.shape) == 4: \n",
    "                im = im.squeeze(0)\n",
    "            im = im.permute(1,2,0)\n",
    "            im = im.numpy()\n",
    "\n",
    "        origin255 = im.copy() * 255\n",
    "        origin255 = origin255.astype(np.uint8)\n",
    "        im = np.array(im, dtype=np.float32) #/ 255.0\n",
    "        \n",
    "        noisy_im = im.copy() # add\n",
    "        noisy255 = noisy_im.copy()\n",
    "        noisy255 = np.clip(noisy255 * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # padding to square\n",
    "        H = noisy_im.shape[0]\n",
    "        W = noisy_im.shape[1]\n",
    "        val_size = (max(H, W) + 31) // 32 * 32\n",
    "        noisy_im = np.pad(\n",
    "            noisy_im,\n",
    "            [[0, val_size - H], [0, val_size - W], [0, 0]],\n",
    "            'reflect')\n",
    "\n",
    "        transformer = transforms.Compose([transforms.ToTensor()])\n",
    "        noisy_im = transformer(noisy_im)\n",
    "        noisy_im = torch.unsqueeze(noisy_im, 0)\n",
    "        noisy_im = noisy_im.cuda()\n",
    "        with torch.no_grad():\n",
    "            n, c, h, w = noisy_im.shape\n",
    "            \n",
    "            net_input, mask = masker.train(noisy_im)\n",
    "            \n",
    "            noisy_output = (network(net_input)*mask).view(n,-1,c,h,w).sum(dim=1)\n",
    "            exp_output = network(noisy_im)\n",
    "        pred_dn = noisy_output[:, :, :H, :W]\n",
    "        pred_exp = exp_output[:, :, :H, :W]\n",
    "        pred_mid = (pred_dn + beta*pred_exp) / (1 + beta)\n",
    "\n",
    "        pred_mid = pred_mid.permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "        pred_mid = pred_mid.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "        pred255_mid = np.clip(pred_mid * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)                   \n",
    "\n",
    "\n",
    "        mid.append(pred255_mid.squeeze())\n",
    "\n",
    "        if len(mid) == cropping.crop_nums:\n",
    "            mid_img = cropping.concat(mid)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        color_mode = 'L'\n",
    "\n",
    "        save_path = os.path.join(save_dir, f\"{name[0]}.png\") \n",
    "        Image.fromarray(mid_img).convert(color_mode).save(save_path)\n",
    "\n",
    "        mid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('b2u')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6574e0f1b25f170aaba03e2351043641f02eb46efc17834ea2ed04c3a8ee1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
