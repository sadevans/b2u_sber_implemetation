{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from arch_unet import UNet\n",
    "import utils as util\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--noisetype\", type=str, default=\"gauss25\", choices=['gauss25', 'gauss5_50', 'poisson30', 'poisson5_50'])\n",
    "parser.add_argument('--checkpoint', type=str, default='./*.pth')\n",
    "parser.add_argument('--test_dir', type=str, default='./data/test')\n",
    "parser.add_argument('--save_test_path', type=str, default='./test')\n",
    "parser.add_argument('--log_name', type=str, default='b2u_unet_g25_112rf20')\n",
    "parser.add_argument('--gpu_devices', default='0', type=str)\n",
    "parser.add_argument('--parallel', action='store_true')\n",
    "parser.add_argument('--n_feature', type=int, default=48)\n",
    "parser.add_argument('--n_channel', type=int, default=1)\n",
    "parser.add_argument(\"--beta\", type=float, default=20.0)\n",
    "parser.add_argument('--dataset_name', type=str)\n",
    "parser.add_argument('--repeat_times', type=int, default=3)\n",
    "\n",
    "opt = parser.parse_args(['--noisetype', 'gauss5_50', \n",
    "                        # '--checkpoint', './pretrained_models/g5-50_112rf20_beta19.4.pth',\n",
    "                        '--checkpoint', './pretrained_models/Confocal_MICE_112rf20_beta19.7.pth',\n",
    "                        '--test_dir', './data/test',\n",
    "                        '--save_test_path', './test',\n",
    "                        '--log_name', 'b2u_sunet_fmdd_112rf20',\n",
    "                        '--beta', '19.4',\n",
    "                        '--dataset_name', 'Crop'])\n",
    "                        \n",
    "systime = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "operation_seed_counter = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_devices\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopyDataset(Dataset):\n",
    "    def __init__(self, img_dir,channels=3, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_filenames = os.listdir(img_dir)\n",
    "        if channels == 1:\n",
    "            self.channels = 0\n",
    "        else:\n",
    "            self.channels = channels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = os.path.split(self.img_filenames[idx])[-1].split('.')[0]\n",
    "\n",
    "        image = cv2.imread(os.path.join(self.img_dir, self.img_filenames[idx]), self.channels)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masker(object):\n",
    "    def __init__(self, width=4, mode='interpolate', mask_type='all'):\n",
    "        self.width = width\n",
    "        self.mode = mode\n",
    "        self.mask_type = mask_type\n",
    "\n",
    "    def mask(self, img, mask_type=None, mode=None):\n",
    "        # This function generates masked images given random masks\n",
    "        if mode is None:\n",
    "            mode = self.mode\n",
    "        if mask_type is None:\n",
    "            mask_type = self.mask_type\n",
    "\n",
    "        n, c, h, w = img.shape\n",
    "        mask = generate_mask(img, width=self.width, mask_type=mask_type)\n",
    "        mask_inv = torch.ones(mask.shape).to(img.device) - mask\n",
    "        if mode == 'interpolate':\n",
    "            masked = interpolate_mask(img, mask, mask_inv)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        net_input = masked\n",
    "        return net_input, mask\n",
    "\n",
    "    def train(self, img):\n",
    "        n, c, h, w = img.shape\n",
    "        tensors = torch.zeros((n,self.width**2,c,h,w), device=img.device)\n",
    "        masks = torch.zeros((n,self.width**2,1,h,w), device=img.device)\n",
    "        for i in range(self.width**2):\n",
    "            x, mask = self.mask(img, mask_type='fix_{}'.format(i))\n",
    "            tensors[:,i,...] = x\n",
    "            masks[:,i,...] = mask\n",
    "        tensors = tensors.view(-1, c, h, w)\n",
    "        masks = masks.view(-1, 1, h, w)\n",
    "        return tensors, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(load_path, network, strict=True):\n",
    "    assert load_path is not None\n",
    "    # logger.info(\"Loading model from [{:s}] ...\".format(load_path))\n",
    "    if isinstance(network, nn.DataParallel) or isinstance(\n",
    "        network, nn.parallel.DistributedDataParallel\n",
    "    ):\n",
    "        network = network.module\n",
    "    load_net = torch.load(load_path)\n",
    "    load_net_clean = OrderedDict()  # remove unnecessary 'module.'\n",
    "    for k, v in load_net.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            load_net_clean[k[7:]] = v\n",
    "        else:\n",
    "            load_net_clean[k] = v\n",
    "    network.load_state_dict(load_net_clean, strict=strict)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentNoise(object):\n",
    "    def __init__(self, style):\n",
    "        print(style)\n",
    "        if style.startswith('gauss'):\n",
    "            self.params = [\n",
    "                float(p) / 255.0 for p in style.replace('gauss', '').split('_')\n",
    "            ]\n",
    "            if len(self.params) == 1:\n",
    "                self.style = \"gauss_fix\"\n",
    "            elif len(self.params) == 2:\n",
    "                self.style = \"gauss_range\"\n",
    "        elif style.startswith('poisson'):\n",
    "            self.params = [\n",
    "                float(p) for p in style.replace('poisson', '').split('_')\n",
    "            ]\n",
    "            if len(self.params) == 1:\n",
    "                self.style = \"poisson_fix\"\n",
    "            elif len(self.params) == 2:\n",
    "                self.style = \"poisson_range\"\n",
    "\n",
    "    def add_train_noise(self, x):\n",
    "        shape = x.shape\n",
    "        if self.style == \"gauss_fix\":\n",
    "            std = self.params[0]\n",
    "            std = std * torch.ones((shape[0], 1, 1, 1), device=x.device)\n",
    "            noise = torch.cuda.FloatTensor(shape, device=x.device)\n",
    "            torch.normal(mean=0.0,\n",
    "                         std=std,\n",
    "                         generator=get_generator(),\n",
    "                         out=noise)\n",
    "            return x + noise\n",
    "        elif self.style == \"gauss_range\":\n",
    "            min_std, max_std = self.params\n",
    "            std = torch.rand(size=(shape[0], 1, 1, 1),\n",
    "                             device=x.device) * (max_std - min_std) + min_std\n",
    "            noise = torch.cuda.FloatTensor(shape, device=x.device)\n",
    "            torch.normal(mean=0, std=std, generator=get_generator(), out=noise)\n",
    "            return x + noise\n",
    "        elif self.style == \"poisson_fix\":\n",
    "            lam = self.params[0]\n",
    "            lam = lam * torch.ones((shape[0], 1, 1, 1), device=x.device)\n",
    "            noised = torch.poisson(lam * x, generator=get_generator()) / lam\n",
    "            return noised\n",
    "        elif self.style == \"poisson_range\":\n",
    "            min_lam, max_lam = self.params\n",
    "            lam = torch.rand(size=(shape[0], 1, 1, 1),\n",
    "                             device=x.device) * (max_lam - min_lam) + min_lam\n",
    "            noised = torch.poisson(lam * x, generator=get_generator()) / lam\n",
    "            return noised\n",
    "\n",
    "    def add_valid_noise(self, x):\n",
    "        shape = x.shape\n",
    "        if self.style == \"gauss_fix\":\n",
    "            std = self.params[0]\n",
    "            return np.array(x + np.random.normal(size=shape) * std,\n",
    "                            dtype=np.float32)\n",
    "        elif self.style == \"gauss_range\":\n",
    "            min_std, max_std = self.params\n",
    "            std = np.random.uniform(low=min_std, high=max_std, size=(1, 1, 1))\n",
    "            return np.array(x + np.random.normal(size=shape) * std,\n",
    "                            dtype=np.float32)\n",
    "        elif self.style == \"poisson_fix\":\n",
    "            lam = self.params[0]\n",
    "            return np.array(np.random.poisson(lam * x) / lam, dtype=np.float32)\n",
    "        elif self.style == \"poisson_range\":\n",
    "            min_lam, max_lam = self.params\n",
    "            lam = np.random.uniform(low=min_lam, high=max_lam, size=(1, 1, 1))\n",
    "            return np.array(np.random.poisson(lam * x) / lam, dtype=np.float32)\n",
    "\n",
    "\n",
    "def space_to_depth(x, block_size):\n",
    "    n, c, h, w = x.size()\n",
    "    unfolded_x = torch.nn.functional.unfold(x, block_size, stride=block_size)\n",
    "    return unfolded_x.view(n, c * block_size**2, h // block_size,\n",
    "                           w // block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(img, width=4, mask_type='random'):\n",
    "    # This function generates random masks with shape (N x C x H/2 x W/2)\n",
    "    n, c, h, w = img.shape\n",
    "    mask = torch.zeros(size=(n * h // width * w // width * width**2, ),\n",
    "                       dtype=torch.int64,\n",
    "                       device=img.device)\n",
    "    idx_list = torch.arange(\n",
    "        0, width**2, 1, dtype=torch.int64, device=img.device)\n",
    "    rd_idx = torch.zeros(size=(n * h // width * w // width, ),\n",
    "                         dtype=torch.int64,\n",
    "                         device=img.device)\n",
    "\n",
    "    if mask_type == 'random':\n",
    "        torch.randint(low=0,\n",
    "                      high=len(idx_list),\n",
    "                      size=(n * h // width * w // width, ),\n",
    "                      device=img.device,\n",
    "                      generator=get_generator(device=img.device),\n",
    "                      out=rd_idx)\n",
    "    elif mask_type == 'batch':\n",
    "        rd_idx = torch.randint(low=0,\n",
    "                               high=len(idx_list),\n",
    "                               size=(n, ),\n",
    "                               device=img.device,\n",
    "                               generator=get_generator(device=img.device)).repeat(h // width * w // width)\n",
    "    elif mask_type == 'all':\n",
    "        rd_idx = torch.randint(low=0,\n",
    "                               high=len(idx_list),\n",
    "                               size=(1, ),\n",
    "                               device=img.device,\n",
    "                               generator=get_generator(device=img.device)).repeat(n * h // width * w // width)\n",
    "    elif 'fix' in mask_type:\n",
    "        index = mask_type.split('_')[-1]\n",
    "        index = torch.from_numpy(np.array(index).astype(\n",
    "            np.int64)).type(torch.int64)\n",
    "        rd_idx = index.repeat(n * h // width * w // width).to(img.device)\n",
    "\n",
    "    rd_pair_idx = idx_list[rd_idx]\n",
    "    rd_pair_idx += torch.arange(start=0,\n",
    "                                end=n * h // width * w // width * width**2,\n",
    "                                step=width**2,\n",
    "                                dtype=torch.int64,\n",
    "                                device=img.device)\n",
    "\n",
    "    mask[rd_pair_idx] = 1\n",
    "\n",
    "    mask = depth_to_space(mask.type_as(img).view(\n",
    "        n, h // width, w // width, width**2).permute(0, 3, 1, 2), block_size=width).type(torch.int64)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def interpolate_mask(tensor, mask, mask_inv):\n",
    "    n, c, h, w = tensor.shape\n",
    "    device = tensor.device\n",
    "    mask = mask.to(device)\n",
    "    kernel = np.array([[0.5, 1.0, 0.5], [1.0, 0.0, 1.0], (0.5, 1.0, 0.5)])\n",
    "\n",
    "    kernel = kernel[np.newaxis, np.newaxis, :, :]\n",
    "    kernel = torch.Tensor(kernel).to(device)\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    filtered_tensor = torch.nn.functional.conv2d(\n",
    "        tensor.view(n*c, 1, h, w), kernel, stride=1, padding=1)\n",
    "\n",
    "    return filtered_tensor.view_as(tensor) * mask + tensor * mask_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_space(x, block_size):\n",
    "    return torch.nn.functional.pixel_shuffle(x, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauss5_50\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "dataset_dir = os.path.join(opt.test_dir, opt.dataset_name)\n",
    "test_dataset = MicroscopyDataset(dataset_dir,opt.n_channel, transform=test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Noise adder\n",
    "noise_adder = AugmentNoise(style=opt.noisetype)\n",
    "# Masker\n",
    "masker = Masker(width=4, mode='interpolate', mask_type='all')\n",
    "# Network\n",
    "network = UNet(in_channels=opt.n_channel,\n",
    "                out_channels=opt.n_channel,\n",
    "                wf=opt.n_feature)\n",
    "if opt.parallel:\n",
    "    network = torch.nn.DataParallel(network)\n",
    "network = network.cuda()\n",
    "# load pre-trained model\n",
    "network = load_network(opt.checkpoint, network, strict=True)\n",
    "beta = opt.beta\n",
    "\n",
    "# turn on eval mode\n",
    "network.eval()\n",
    "\n",
    "# validation\n",
    "save_test_path = os.path.join(opt.save_test_path, opt.dataset_name)\n",
    "os.makedirs(save_test_path, exist_ok=True)\n",
    "\n",
    "validation_path = os.path.join(save_test_path, opt.log_name)\n",
    "os.makedirs(validation_path, exist_ok=True)\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = validation_path\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "repeat_times = opt.repeat_times\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    for im, name in tqdm(test_dataloader):\n",
    "        # print('im shape', im.shape)\n",
    "        \n",
    "        if type(im) == torch.Tensor:\n",
    "            \n",
    "            if len(im.shape) == 4: \n",
    "                im = im.squeeze(0)\n",
    "            im = im.permute(1,2,0)\n",
    "            im = im.numpy()\n",
    "        # print(im.shape)\n",
    "        origin255 = im.copy() * 255\n",
    "        origin255 = origin255.astype(np.uint8)\n",
    "        im = np.array(im, dtype=np.float32) #/ 255.0\n",
    "        # noisy_im = noise_adder.add_valid_noise(im)\n",
    "        \n",
    "        noisy_im = im.copy() # add\n",
    "        # print('noisy_im.shape ', noisy_im.shape)\n",
    "        noisy255 = noisy_im.copy()\n",
    "        noisy255 = np.clip(noisy255 * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # padding to square\n",
    "        H = noisy_im.shape[0]\n",
    "        W = noisy_im.shape[1]\n",
    "        val_size = (max(H, W) + 31) // 32 * 32\n",
    "        noisy_im = np.pad(\n",
    "            noisy_im,\n",
    "            [[0, val_size - H], [0, val_size - W], [0, 0]],\n",
    "            'reflect')\n",
    "\n",
    "        transformer = transforms.Compose([transforms.ToTensor()])\n",
    "        noisy_im = transformer(noisy_im)\n",
    "        noisy_im = torch.unsqueeze(noisy_im, 0)\n",
    "        noisy_im = noisy_im.cuda()\n",
    "        with torch.no_grad():\n",
    "            n, c, h, w = noisy_im.shape\n",
    "            # print('noisy_im.shape ', noisy_im.shape)\n",
    "            net_input, mask = masker.train(noisy_im)\n",
    "            # print('net_input shape', net_input.shape)\n",
    "            noisy_output = (network(net_input)*mask).view(n,-1,c,h,w).sum(dim=1)\n",
    "            exp_output = network(noisy_im)\n",
    "        pred_dn = noisy_output[:, :, :H, :W]\n",
    "        pred_exp = exp_output[:, :, :H, :W]\n",
    "        pred_mid = (pred_dn + beta*pred_exp) / (1 + beta)\n",
    "\n",
    "        pred_dn = pred_dn.permute(0, 2, 3, 1)\n",
    "        pred_exp = pred_exp.permute(0, 2, 3, 1)\n",
    "        pred_mid = pred_mid.permute(0, 2, 3, 1)\n",
    "\n",
    "        pred_dn = pred_dn.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "        pred_exp = pred_exp.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "        pred_mid = pred_mid.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "\n",
    "        pred255_dn = np.clip(pred_dn * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "        pred255_exp = np.clip(pred_exp * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "        pred255_mid = np.clip(pred_mid * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)                   \n",
    "\n",
    "        \n",
    "\n",
    "        # visualization\n",
    "        # print('noisy255 shape', noisy255.shape)\n",
    "        if opt.n_channel == 1:\n",
    "            color_mode = 'L'\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_clean.png\")\n",
    "            Image.fromarray(origin255.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_noisy.png\")    \n",
    "            Image.fromarray(noisy255.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_dn.png\") \n",
    "            Image.fromarray(pred255_dn.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_exp.png\") \n",
    "            Image.fromarray(pred255_exp.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_mid.png\") \n",
    "            Image.fromarray(pred255_mid.squeeze()).convert(color_mode).save(save_path)\n",
    "        else:\n",
    "            color_mode = 'L'\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_clean.png\")\n",
    "            Image.fromarray(origin255).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_noisy.png\")    \n",
    "            Image.fromarray(noisy255).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_dn.png\") \n",
    "            Image.fromarray(pred255_dn).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_exp.png\") \n",
    "            Image.fromarray(pred255_exp).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_mid.png\") \n",
    "            Image.fromarray(pred255_mid).convert(color_mode).save(save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('./data/test/Microscopy/crop_noisy.tiff')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./data/test/Crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./data/test/Crop/crop_.tiff',image[:480,:640,:] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('b2u')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6574e0f1b25f170aaba03e2351043641f02eb46efc17834ea2ed04c3a8ee1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
