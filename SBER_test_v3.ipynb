{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from arch_unet import UNet\n",
    "import utils as util\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Sber_utils import Masker, load_network, generate_mask, interpolate_mask, depth_to_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--noisetype\", type=str, default=\"gauss25\", choices=['gauss25', 'gauss5_50', 'poisson30', 'poisson5_50'])\n",
    "parser.add_argument('--checkpoint', type=str, default='./*.pth')\n",
    "parser.add_argument('--test_dir', type=str, default='./data/test')\n",
    "parser.add_argument('--save_test_path', type=str, default='./test')\n",
    "parser.add_argument('--log_name', type=str, default='b2u_unet_g25_112rf20')\n",
    "parser.add_argument('--gpu_devices', default='0', type=str)\n",
    "parser.add_argument('--parallel', action='store_true')\n",
    "parser.add_argument('--n_feature', type=int, default=48)\n",
    "parser.add_argument('--n_channel', type=int, default=1)\n",
    "parser.add_argument(\"--beta\", type=float, default=20.0)\n",
    "parser.add_argument('--dataset_name', type=str)\n",
    "parser.add_argument('--repeat_times', type=int, default=3)\n",
    "\n",
    "opt = parser.parse_args(['--noisetype', 'gauss5_50', \n",
    "                        # '--checkpoint', './pretrained_models/g5-50_112rf20_beta19.4.pth',\n",
    "                        '--checkpoint', './experiments/my_models/2023-07-13-14-50/models/epoch_model_100.pth',\n",
    "                        '--test_dir', './data/test',\n",
    "                        '--save_test_path', './test',\n",
    "                        '--log_name', 'b2u_sunet_fmdd_112rf20',\n",
    "                        '--beta', '19.4',\n",
    "                        '--dataset_name', 'small_test'])\n",
    "                        \n",
    "systime = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "operation_seed_counter = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_devices\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopyDataset(Dataset):\n",
    "    def __init__(self, img_dir,channels=3, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_filenames = os.listdir(img_dir)\n",
    "        if channels == 1:\n",
    "            self.channels = 0\n",
    "        else:\n",
    "            self.channels = channels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = os.path.split(self.img_filenames[idx])[-1].split('.')[0]\n",
    "\n",
    "        image = cv2.imread(os.path.join(self.img_dir, self.img_filenames[idx]), self.channels)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "dataset_dir = os.path.join(opt.test_dir, opt.dataset_name)\n",
    "test_dataset = MicroscopyDataset(dataset_dir,opt.n_channel, transform=test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Masker\n",
    "masker = Masker(width=4, mode='interpolate', mask_type='all')\n",
    "# Network\n",
    "network = UNet(in_channels=opt.n_channel,\n",
    "                out_channels=opt.n_channel,\n",
    "                wf=opt.n_feature)\n",
    "if opt.parallel:\n",
    "    network = torch.nn.DataParallel(network)\n",
    "network = network.cuda()\n",
    "# load pre-trained model\n",
    "network = load_network(opt.checkpoint, network, strict=True)\n",
    "beta = opt.beta\n",
    "\n",
    "# turn on eval mode\n",
    "network.eval()\n",
    "\n",
    "# validation\n",
    "save_test_path = os.path.join(opt.save_test_path, opt.dataset_name)\n",
    "os.makedirs(save_test_path, exist_ok=True)\n",
    "\n",
    "validation_path = os.path.join(save_test_path, opt.log_name)\n",
    "os.makedirs(validation_path, exist_ok=True)\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 108.00 GiB (GPU 0; 10.92 GiB total capacity; 4.64 GiB already allocated; 5.58 GiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m     net_input, mask \u001b[38;5;241m=\u001b[39m masker\u001b[38;5;241m.\u001b[39mtrain(noisy_im)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# print('net_input shape', net_input.shape)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     noisy_output \u001b[38;5;241m=\u001b[39m (\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mmask)\u001b[38;5;241m.\u001b[39mview(n,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,c,h,w)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m     exp_output \u001b[38;5;241m=\u001b[39m network(noisy_im)\n\u001b[1;32m     49\u001b[0m pred_dn \u001b[38;5;241m=\u001b[39m noisy_output[:, :, :H, :W]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/SSD/vscode/Blind2Unblind/arch_unet.py:37\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m blocks \u001b[39m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m blocks\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m---> 37\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead(x)\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m i, down \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_path):\n\u001b[1;32m     39\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmax_pool2d(x, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/SSD/vscode/Blind2Unblind/arch_unet.py:62\u001b[0m, in \u001b[0;36mLR.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 62\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(x)\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 108.00 GiB (GPU 0; 10.92 GiB total capacity; 4.64 GiB already allocated; 5.58 GiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = validation_path\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "repeat_times = opt.repeat_times\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    for im, name in tqdm(test_dataloader):\n",
    "        # print('im shape', im.shape)\n",
    "        \n",
    "        if type(im) == torch.Tensor:\n",
    "            \n",
    "            if len(im.shape) == 4: \n",
    "                im = im.squeeze(0)\n",
    "            im = im.permute(1,2,0)\n",
    "            im = im.numpy()\n",
    "        # print(im.shape)\n",
    "        origin255 = im.copy() * 255\n",
    "        origin255 = origin255.astype(np.uint8)\n",
    "        im = np.array(im, dtype=np.float32) #/ 255.0\n",
    "        # noisy_im = noise_adder.add_valid_noise(im)\n",
    "        \n",
    "        noisy_im = im.copy() # add\n",
    "        # print('noisy_im.shape ', noisy_im.shape)\n",
    "        noisy255 = noisy_im.copy()\n",
    "        noisy255 = np.clip(noisy255 * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # padding to square\n",
    "        H = noisy_im.shape[0]\n",
    "        W = noisy_im.shape[1]\n",
    "        val_size = (max(H, W) + 31) // 32 * 32\n",
    "        noisy_im = np.pad(\n",
    "            noisy_im,\n",
    "            [[0, val_size - H], [0, val_size - W], [0, 0]],\n",
    "            'reflect')\n",
    "\n",
    "        transformer = transforms.Compose([transforms.ToTensor()])\n",
    "        noisy_im = transformer(noisy_im)\n",
    "        noisy_im = torch.unsqueeze(noisy_im, 0)\n",
    "        noisy_im = noisy_im.cuda()\n",
    "        with torch.no_grad():\n",
    "            n, c, h, w = noisy_im.shape\n",
    "            # print('noisy_im.shape ', noisy_im.shape)\n",
    "            net_input, mask = masker.train(noisy_im)\n",
    "            # print('net_input shape', net_input.shape)\n",
    "            noisy_output = (network(net_input)*mask).view(n,-1,c,h,w).sum(dim=1)\n",
    "            exp_output = network(noisy_im)\n",
    "        pred_dn = noisy_output[:, :, :H, :W]\n",
    "        pred_exp = exp_output[:, :, :H, :W]\n",
    "        pred_mid = (pred_dn + beta*pred_exp) / (1 + beta)\n",
    "\n",
    "        pred_dn = pred_dn.permute(0, 2, 3, 1)\n",
    "        pred_exp = pred_exp.permute(0, 2, 3, 1)\n",
    "        pred_mid = pred_mid.permute(0, 2, 3, 1)\n",
    "\n",
    "        pred_dn = pred_dn.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "        pred_exp = pred_exp.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "        pred_mid = pred_mid.cpu().data.clamp(0, 1).numpy().squeeze(0)\n",
    "\n",
    "        pred255_dn = np.clip(pred_dn * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "        pred255_exp = np.clip(pred_exp * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)\n",
    "        pred255_mid = np.clip(pred_mid * 255.0 + 0.5, 0,\n",
    "                            255).astype(np.uint8)                   \n",
    "\n",
    "        \n",
    "\n",
    "        # visualization\n",
    "        # print('noisy255 shape', noisy255.shape)\n",
    "        if opt.n_channel == 1:\n",
    "            color_mode = 'L'\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_clean.png\")\n",
    "            Image.fromarray(origin255.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_noisy.png\")    \n",
    "            Image.fromarray(noisy255.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_dn.png\") \n",
    "            Image.fromarray(pred255_dn.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_exp.png\") \n",
    "            Image.fromarray(pred255_exp.squeeze()).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_mid.png\") \n",
    "            Image.fromarray(pred255_mid.squeeze()).convert(color_mode).save(save_path)\n",
    "        else:\n",
    "            color_mode = 'L'\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_clean.png\")\n",
    "            Image.fromarray(origin255).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_noisy.png\")    \n",
    "            Image.fromarray(noisy255).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_dn.png\") \n",
    "            Image.fromarray(pred255_dn).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_exp.png\") \n",
    "            Image.fromarray(pred255_exp).convert(color_mode).save(save_path)\n",
    "\n",
    "            save_path = os.path.join(save_dir, f\"{name}-{i}_mid.png\") \n",
    "            Image.fromarray(pred255_mid).convert(color_mode).save(save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('b2u')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6574e0f1b25f170aaba03e2351043641f02eb46efc17834ea2ed04c3a8ee1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
